{
	"corpora": {
		"text8": {
			"description": "Cleaned small sample from wikipedia",
			"checksum": "f407f5aed497fc3b0fb33b98c4f9d855",
			"file_name": "text8"
		},
		"fake-news": {
			"description": "It contains text and metadata scraped from 244 websites tagged as 'bullshit' here by the BS Detector Chrome Extension by Daniel Sieradski.",
			"checksum": "a61f985190ba361defdfc3fef616b9cd",
			"file_name": "fake.csv",
			"source": "Kaggle"
		}
	},
	"models": {
		"glove-wiki-gigaword-50": {
			"description": "Pre-trained vectors ,Wikipedia 2014 + Gigaword 5,6B tokens, 400K vocab, uncased. https://nlp.stanford.edu/projects/glove/"
			"parameters": "dimension = 50",
			"preprocessing": "Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`",
			"papers": "https://nlp.stanford.edu/pubs/glove.pdf",
			"checksum": "b269a9c8b16c3178d3d0651fd68c3fe9",
			"file_name": "glove-wiki-gigaword-50.txt"
		}
	
	}
}
